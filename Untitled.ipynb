{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb6d69-189c-450a-9a67-c17fe6afe206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 4 : Transformation des donnÃ©es et dÃ©tection d'alertes\n",
    "\n",
    "# 1. Importations\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "\n",
    "# 2. CrÃ©ation de la session Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaWeatherTransformation\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EXERCICE 4 : TRANSFORMATION DES DONNÃ‰ES ET DÃ‰TECTION D'ALERTES\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nConfiguration Spark pour Kafka...\")\n",
    "\n",
    "# 3. Lecture du stream Kafka\n",
    "kafka_df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"weather.stream\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "print(\"âœ“ Connexion Ã  Kafka Ã©tablie\")\n",
    "print(f\"  Topic: weather.stream\")\n",
    "print(f\"  Broker: kafka:9092\")\n",
    "\n",
    "# 4. SchÃ©ma des donnÃ©es JSON\n",
    "json_schema = StructType([\n",
    "    StructField(\"exercise\", IntegerType(), True),\n",
    "    StructField(\"timestamp\", DoubleType(), True),\n",
    "    StructField(\"event_time\", StringType(), True),\n",
    "    StructField(\"latitude\", FloatType(), True),\n",
    "    StructField(\"longitude\", FloatType(), True),\n",
    "    StructField(\"temperature\", FloatType(), True),\n",
    "    StructField(\"windspeed\", FloatType(), True),\n",
    "    StructField(\"winddirection\", IntegerType(), True),\n",
    "    StructField(\"weathercode\", IntegerType(), True),\n",
    "    StructField(\"is_day\", IntegerType(), True),\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True)\n",
    "])\n",
    "\n",
    "# 5. Parsing des donnÃ©es JSON\n",
    "parsed_df = kafka_df.select(\n",
    "    from_json(col(\"value\").cast(\"string\"), json_schema).alias(\"data\"),\n",
    "    col(\"timestamp\").alias(\"kafka_timestamp\"),\n",
    "    col(\"partition\").alias(\"kafka_partition\"),\n",
    "    col(\"offset\").alias(\"kafka_offset\")\n",
    ").select(\"data.*\", \"kafka_timestamp\", \"kafka_partition\", \"kafka_offset\")\n",
    "\n",
    "print(\"âœ“ SchÃ©ma JSON dÃ©fini\")\n",
    "print(\"âœ“ Parsing des donnÃ©es configurÃ©\")\n",
    "\n",
    "# 6. Transformation des donnÃ©es (ALERTES)\n",
    "print(\"\\nðŸ“Š TRANSFORMATION DES DONNÃ‰ES :\")\n",
    "print(\"  - Vent faible (< 10 m/s) â†’ level_0\")\n",
    "print(\"  - Vent modÃ©rÃ© (10-20 m/s) â†’ level_1\")\n",
    "print(\"  - Vent fort (> 20 m/s) â†’ level_2\")\n",
    "print(\"  - TempÃ©rature normale (< 25Â°C) â†’ level_0\")\n",
    "print(\"  - Chaleur modÃ©rÃ©e (25-35Â°C) â†’ level_1\")\n",
    "print(\"  - Canicule (> 35Â°C) â†’ level_2\")\n",
    "\n",
    "transformed_df = parsed_df.withColumn(\n",
    "    \"wind_alert_level\",\n",
    "    when(col(\"windspeed\") < 10, \"level_0\")\n",
    "    .when((col(\"windspeed\") >= 10) & (col(\"windspeed\") <= 20), \"level_1\")\n",
    "    .otherwise(\"level_2\")\n",
    ").withColumn(\n",
    "    \"heat_alert_level\",\n",
    "    when(col(\"temperature\") < 25, \"level_0\")\n",
    "    .when((col(\"temperature\") >= 25) & (col(\"temperature\") <= 35), \"level_1\")\n",
    "    .otherwise(\"level_2\")\n",
    ").withColumn(\n",
    "    \"processing_time\", current_timestamp()\n",
    ").withColumn(\n",
    "    \"event_timestamp\", to_timestamp(col(\"event_time\"))\n",
    ").select(\n",
    "    \"event_timestamp\",\n",
    "    \"processing_time\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"temperature\",\n",
    "    \"windspeed\",\n",
    "    \"winddirection\",\n",
    "    \"wind_alert_level\",\n",
    "    \"heat_alert_level\",\n",
    "    \"weathercode\",\n",
    "    \"city\",\n",
    "    \"country\",\n",
    "    \"kafka_partition\",\n",
    "    \"kafka_offset\",\n",
    "    \"source\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Logique de transformation appliquÃ©e\")\n",
    "print(\"âœ“ Niveaux d'alerte calculÃ©s\")\n",
    "\n",
    "# 7. Affichage du rÃ©sultat\n",
    "print(\"\\nðŸ‘ï¸ AFFICHAGE DES DONNÃ‰ES TRANSFORMÃ‰ES :\")\n",
    "print(\"  (Streaming en temps rÃ©el - Ctrl+C dans Jupyter pour arrÃªter)\")\n",
    "\n",
    "query = transformed_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STREAMING SPARK DÃ‰MARRÃ‰ !\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nðŸ“‹ Colonnes produites :\")\n",
    "print(\"  - event_timestamp : timestamp de l'Ã©vÃ©nement\")\n",
    "print(\"  - processing_time : heure de traitement\")\n",
    "print(\"  - temperature : tempÃ©rature en Â°C\")\n",
    "print(\"  - windspeed : vitesse du vent en m/s\")\n",
    "print(\"  - wind_alert_level : niveau d'alerte vent (level_0/1/2)\")\n",
    "print(\"  - heat_alert_level : niveau d'alerte chaleur (level_0/1/2)\")\n",
    "print(\"  - city, country : localisation\")\n",
    "print(\"  - kafka_partition, kafka_offset : position dans Kafka\")\n",
    "\n",
    "print(\"\\nâ³ Attente des donnÃ©es... (les premiÃ¨res donnÃ©es apparaÃ®tront dans 10 secondes)\")\n",
    "\n",
    "# 8. Attente\n",
    "try:\n",
    "    query.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nArrÃªt du streaming Spark...\")\n",
    "    query.stop()\n",
    "    spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586c4ac-7e01-463e-a997-ec4fe7931f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã‰criture des donnÃ©es transformÃ©es dans le nouveau topic Kafka\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰CRITURE DANS LE TOPIC weather_transformed\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from pyspark.sql.functions import to_json, struct\n",
    "\n",
    "# PrÃ©paration des donnÃ©es pour Kafka\n",
    "kafka_output_df = transformed_df.select(\n",
    "    to_json(struct(\n",
    "        \"event_timestamp\",\n",
    "        \"processing_time\",\n",
    "        \"latitude\",\n",
    "        \"longitude\", \n",
    "        \"temperature\",\n",
    "        \"windspeed\",\n",
    "        \"winddirection\",\n",
    "        \"wind_alert_level\",\n",
    "        \"heat_alert_level\",\n",
    "        \"weathercode\",\n",
    "        \"city\",\n",
    "        \"country\"\n",
    "    )).alias(\"value\")\n",
    ")\n",
    "\n",
    "# Ã‰criture dans Kafka\n",
    "query_kafka = kafka_output_df \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"topic\", \"weather_transformed\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/kafka-checkpoint\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"âœ… Ã‰criture Kafka dÃ©marrÃ©e\")\n",
    "print(\"   Topic: weather_transformed\")\n",
    "print(\"   Format: JSON\")\n",
    "\n",
    "# Garder les deux queries actives\n",
    "import time\n",
    "print(\"\\nðŸ“Š Les deux streams tournent :\")\n",
    "print(\"   1. Affichage console (donnÃ©es transformÃ©es)\")\n",
    "print(\"   2. Ã‰criture Kafka (weather_transformed)\")\n",
    "print(\"\\nPour arrÃªter : Interrompre le kernel (bouton carrÃ©)\")\n",
    "\n",
    "# Attendre\n",
    "try:\n",
    "    query_kafka.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"ArrÃªt des streams...\")\n",
    "    query.stop()\n",
    "    query_kafka.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edde612-fdab-434f-9292-63cda4f205d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercice 5 : AgrÃ©gats en temps rÃ©el avec Spark\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXERCICE 5 : AGRÃ‰GATS EN TEMPS RÃ‰EL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. FenÃªtres glissantes (5 minutes)\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "window_spec = Window.partitionBy(\"city\").orderBy(\"event_timestamp\").rangeBetween(-300, 0)\n",
    "\n",
    "aggregated_df = transformed_df \\\n",
    "    .withWatermark(\"event_timestamp\", \"1 minute\") \\\n",
    "    .groupBy(\n",
    "        window(col(\"event_timestamp\"), \"5 minutes\", \"1 minute\"),\n",
    "        col(\"city\"),\n",
    "        col(\"country\")\n",
    "    ) \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"total_messages\"),\n",
    "        F.avg(\"temperature\").alias(\"avg_temperature\"),\n",
    "        F.min(\"temperature\").alias(\"min_temperature\"),\n",
    "        F.max(\"temperature\").alias(\"max_temperature\"),\n",
    "        F.avg(\"windspeed\").alias(\"avg_windspeed\"),\n",
    "        F.sum(when(col(\"wind_alert_level\") != \"level_0\", 1).otherwise(0)).alias(\"wind_alerts_count\"),\n",
    "        F.sum(when(col(\"heat_alert_level\") != \"level_0\", 1).otherwise(0)).alias(\"heat_alerts_count\")\n",
    "    )\n",
    "\n",
    "print(\"ðŸ“Š MÃ©triques calculÃ©es :\")\n",
    "print(\"  - Nombre total de messages par fenÃªtre\")\n",
    "print(\"  - TempÃ©rature moyenne/min/max\")\n",
    "print(\"  - Nombre d'alertes vent et chaleur\")\n",
    "print(\"  - FenÃªtre glissante : 5 minutes, dÃ©calage 1 minute\")\n",
    "\n",
    "# 2. Ã‰criture dans un nouveau topic Kafka (weather_transformed)\n",
    "print(\"\\nðŸ“¤ Ã‰CRITURE DANS KAFKA :\")\n",
    "print(\"  Topic: weather_transformed\")\n",
    "\n",
    "kafka_output_df = transformed_df.select(\n",
    "    to_json(struct(\"*\")).alias(\"value\")\n",
    ")\n",
    "\n",
    "# Pour Ã©crire dans Kafka (dÃ©commenter quand vous Ãªtes prÃªt)\n",
    "# query_output = kafka_output_df \\\n",
    "#     .writeStream \\\n",
    "#     .format(\"kafka\") \\\n",
    "#     .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "#     .option(\"topic\", \"weather_transformed\") \\\n",
    "#     .option(\"checkpointLocation\", \"/tmp/checkpoint\") \\\n",
    "#     .start()\n",
    "\n",
    "# 3. Affichage des agrÃ©gats\n",
    "query_agg = aggregated_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .trigger(processingTime=\"30 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"\\nâ³ DÃ©marrage des agrÃ©gats en temps rÃ©el...\")\n",
    "\n",
    "try:\n",
    "    query_agg.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nArrÃªt des agrÃ©gats...\")\n",
    "    query_agg.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3783a6-e8f8-487f-bfbf-1bd76e7f9e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
