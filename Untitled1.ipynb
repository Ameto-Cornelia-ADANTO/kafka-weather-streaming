{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb601538-bb83-4d93-b4e8-a93518493e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================\n",
    "# EXERCICE 4 CORRIGÃ‰ : AVEC DÃ‰CLENCHEMENT FORCÃ‰\n",
    "# =================================================================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "\n",
    "# 1. CrÃ©ation de la session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaWeatherProcessing\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1\") \\\n",
    "    .config(\"spark.sql.streaming.forceDeleteTempCheckpointLocation\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DÃ‰MARRAGE DU TRAITEMENT SPARK STREAMING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 2. Lecture depuis Kafka\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"weather.stream\") \\\n",
    "    .option(\"startingOffsets\", \"latest\")  # Commencer depuis maintenant\n",
    "    .load()\n",
    "\n",
    "print(\"âœ… Connexion Ã  Kafka Ã©tablie\")\n",
    "\n",
    "# 3. SchÃ©ma\n",
    "schema = StructType([\n",
    "    StructField(\"exercise\", IntegerType()),\n",
    "    StructField(\"timestamp\", DoubleType()),\n",
    "    StructField(\"event_time\", StringType()),\n",
    "    StructField(\"latitude\", FloatType()),\n",
    "    StructField(\"longitude\", FloatType()),\n",
    "    StructField(\"temperature\", FloatType()),\n",
    "    StructField(\"windspeed\", FloatType()),\n",
    "    StructField(\"city\", StringType()),\n",
    "    StructField(\"country\", StringType())\n",
    "])\n",
    "\n",
    "# 4. Transformation\n",
    "parsed = df.select(\n",
    "    from_json(col(\"value\").cast(\"string\"), schema).alias(\"data\"),\n",
    "    col(\"timestamp\").alias(\"kafka_ts\")\n",
    ").select(\"data.*\", \"kafka_ts\")\n",
    "\n",
    "# Calcul des alertes\n",
    "transformed = parsed \\\n",
    "    .withColumn(\"event_timestamp\", to_timestamp(col(\"event_time\"))) \\\n",
    "    .withColumn(\"processing_time\", current_timestamp()) \\\n",
    "    .withColumn(\"wind_alert_level\",\n",
    "        when(col(\"windspeed\") < 10, \"level_0\")\n",
    "        .when((col(\"windspeed\") >= 10) & (col(\"windspeed\") <= 20), \"level_1\")\n",
    "        .otherwise(\"level_2\")\n",
    "    ) \\\n",
    "    .withColumn(\"heat_alert_level\",\n",
    "        when(col(\"temperature\") < 25, \"level_0\")\n",
    "        .when((col(\"temperature\") >= 25) & (col(\"temperature\") <= 35), \"level_1\")\n",
    "        .otherwise(\"level_2\")\n",
    "    )\n",
    "\n",
    "# 5. AFFICHAGE DIRECT (pour voir que Ã§a marche)\n",
    "print(\"\\nðŸ‘ï¸ AFFICHAGE DES PREMIÃˆRES DONNÃ‰ES :\")\n",
    "\n",
    "display_query = transformed \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .trigger(processingTime=\"3 seconds\")  # TRÃˆS IMPORTANT : court intervalle\n",
    "    .start()\n",
    "\n",
    "print(\"Stream d'affichage dÃ©marrÃ©. Attente 10 secondes pour les premiÃ¨res donnÃ©es...\")\n",
    "\n",
    "# Attendre un peu pour voir les premiÃ¨res donnÃ©es\n",
    "time.sleep(10)\n",
    "\n",
    "# 6. Ã‰CRITURE DANS weather_transformed\n",
    "print(\"\\nðŸ“¤ Ã‰CRITURE DANS LE TOPIC weather_transformed\")\n",
    "\n",
    "# VÃ©rifier/crÃ©er le topic\n",
    "import subprocess\n",
    "result = subprocess.run([\n",
    "    \"docker\", \"exec\", \"kafka\",\n",
    "    \"kafka-topics\", \"--create\", \"--if-not-exists\",\n",
    "    \"--topic\", \"weather_transformed\",\n",
    "    \"--bootstrap-server\", \"kafka:9092\",\n",
    "    \"--partitions\", \"3\",\n",
    "    \"--replication-factor\", \"1\"\n",
    "], capture_output=True, text=True)\n",
    "\n",
    "print(f\"Topic: {result.stdout if result.stdout else 'existe dÃ©jÃ '}\")\n",
    "\n",
    "# PrÃ©paration pour Kafka\n",
    "kafka_output = transformed.select(\n",
    "    to_json(struct(\n",
    "        \"event_timestamp\",\n",
    "        \"temperature\",\n",
    "        \"windspeed\",\n",
    "        \"wind_alert_level\",\n",
    "        \"heat_alert_level\",\n",
    "        \"city\",\n",
    "        \"country\"\n",
    "    )).alias(\"value\")\n",
    ")\n",
    "\n",
    "# Stream vers Kafka\n",
    "kafka_query = kafka_output \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"topic\", \"weather_transformed\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/spark-checkpoint\") \\\n",
    "    .trigger(processingTime=\"5 seconds\")  # Court intervalle\n",
    "    .start()\n",
    "\n",
    "print(\"âœ… Stream Kafka dÃ©marrÃ©\")\n",
    "\n",
    "# 7. Attendre et montrer que Ã§a fonctionne\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SYSTÃˆME ACTIF - En attente de donnÃ©es...\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nPour tester, envoyez des donnÃ©es avec:\")\n",
    "print(\"  python exercise3.py 48.8566 2.3522 5\")\n",
    "print(\"\\nOu vÃ©rifiez avec:\")\n",
    "print(\"  docker exec kafka kafka-console-consumer --topic weather_transformed --bootstrap-server kafka:9092\")\n",
    "\n",
    "# Attendre un moment pour voir l'activitÃ©\n",
    "try:\n",
    "    for i in range(30):  # 30 secondes\n",
    "        print(f\"\\rEn attente... {30-i}s restantes\", end=\"\")\n",
    "        time.sleep(1)\n",
    "    print(\"\\n\\nTemps Ã©coulÃ©. ArrÃªt des streams...\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nArrÃªt demandÃ©...\")\n",
    "\n",
    "# Nettoyage\n",
    "display_query.stop()\n",
    "kafka_query.stop()\n",
    "spark.stop()\n",
    "\n",
    "print(\"âœ… Traitement terminÃ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3317df32-ad77-4cf5-a74b-a427f6184dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33279998-8db1-46e8-8d42-6ee63f7cb60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
